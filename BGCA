import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F

from sklearn.cross_decomposition import PLSRegression
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler
from pyts.image import GramianAngularField


class CARS:
    """
    Competitive Adaptive Reweighted Sampling (CARS) for variable selection
    based on PLS regression.
    """

    def __init__(self, iteration=50, n_comps=20, cv=10, prob=0.95):
        self.iteration = iteration
        self.n_comps = n_comps
        self.cv = cv
        self.prob = prob
        self.W_best = None

    def fit(self, X, y):
        """
        Fit CARS model and select optimal variables.

        Parameters
        ----------
        X : ndarray of shape (N, D)
            Input feature matrix.
        y : ndarray of shape (N,)
            Target vector.
        """
        y = np.asarray(y).reshape(-1)
        N, D = X.shape
        prob = self.prob

        # Exponential decay parameters for variable elimination
        a = np.power((D / 2), (1 / (self.iteration - 1)))
        k = (np.log(D / 2)) / (self.iteration - 1)
        r = [
            max(1, int(round(a * np.exp(-(k * i)) * D)))
            for i in range(1, self.iteration + 1)
        ]

        weights = np.ones(D) / D
        RMSECV = []
        idWs = []

        for i in range(self.iteration):
            # Random calibration samples
            idCal = np.random.choice(
                np.arange(N),
                size=max(4, int(prob * N)),
                replace=False
            )

            # Weighted variable sampling
            idW = np.random.choice(
                np.arange(D),
                size=min(r[i], D),
                p=weights / weights.sum(),
                replace=False
            )
            idWs.append(idW)

            X_cal = X[np.ix_(idCal, idW)]
            y_cal = y[idCal].reshape(-1, 1)

            # Determine valid number of PLS components
            comp = min(self.n_comps, X_cal.shape[1], len(idCal) - 1)
            if comp < 1:
                comp = 1

            pls = PLSRegression(n_components=comp)
            pls.fit(X_cal, y_cal)

            # Update variable weights using regression coefficients
            absolute = np.abs(pls.coef_).reshape(-1)
            if np.sum(absolute) == 0:
                weights[idW] = 1.0 / len(idW)
            else:
                weights[idW] = absolute / np.sum(absolute)

            # Cross-validated RMSE
            mse = -cross_val_score(
                pls,
                X_cal,
                y_cal,
                cv=min(self.cv, len(idCal)),
                scoring="neg_mean_squared_error",
            )
            rmse = float(np.mean(np.sqrt(mse)))
            RMSECV.append(rmse)

        # Select variable subset with minimum RMSECV
        best_index = int(np.argmin(RMSECV))
        self.W_best = idWs[best_index]
        return self

    def transform(self, X):
        """
        Reduce input matrix using selected variables.
        """
        if self.W_best is None:
            raise ValueError("CARS: fit() must be called before transform()")
        return X[:, self.W_best]

    def fit_transform(self, X, y):
        """
        Fit CARS model and transform data.
        """
        self.fit(X, y)
        return self.transform(X)


class CNN2D(nn.Module):
    """
    2D CNN feature extractor using Gramian Angular Field (GAF)
    representation of 1D signals.
    """

    def __init__(self, image_size=(1024, 1024), num_channels=1):
        super(CNN2D, self).__init__()
        self.image_size = image_size
        self.num_channels = num_channels

        self.convs = nn.Sequential(
            nn.Conv2d(num_channels, 16, kernel_size=7, padding=3),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(16, 32, kernel_size=7, padding=3),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(32, 64, kernel_size=7, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),
        )

    def _gaf(self, x1d):
        """
        Convert a 1D signal to a Gramian Angular Field image.
        """
        transformer = GramianAngularField(
            image_size=self.image_size[0],
            method="summation"
        )
        x1d = np.array(x1d).reshape(1, -1)
        gram = transformer.fit_transform(x1d)[0]  # (H, W)
        return gram

    def forward(self, x1d_batch):
        """
        Parameters
        ----------
        x1d_batch : Tensor of shape (batch, length)

        Returns
        -------
        Tensor of shape (batch, C) after global average pooling.
        """
        batch_size = x1d_batch.shape[0]
        device = x1d_batch.device

        grams = []
        for i in range(batch_size):
            gaf_np = self._gaf(
                x1d_batch[i].detach().cpu().numpy()
            )
            grams.append(gaf_np)

        grams_np = np.stack(grams, axis=0)                 # (batch, H, W)
        grams_tensor = torch.tensor(
            grams_np,
            dtype=torch.float32,
            device=device
        ).unsqueeze(1)                                     # (batch, 1, H, W)

        feats = self.convs(grams_tensor)                   # (batch, C, h, w)
        gap = F.adaptive_avg_pool2d(feats, (1, 1))
        gap = gap.squeeze(-1).squeeze(-1)                  # (batch, C)
        return gap

    def extract_features(self, dataset: np.ndarray, batch_size=16):
        """
        Extract CNN features from a full dataset.
        """
        self.eval()
        device = next(self.parameters()).device
        outputs = []

        with torch.no_grad():
            for i in range(0, len(dataset), batch_size):
                batch = dataset[i:i + batch_size]
                batch_tensor = torch.tensor(
                    batch,
                    dtype=torch.float32,
                    device=device
                )
                out = self(batch_tensor)
                outputs.append(out.cpu())

        return torch.cat(outputs, dim=0).numpy()


class BiMamba2_1D(nn.Module):
    """
    Bidirectional Mamba v2 block for 1D sequence feature extraction.
    """

    def __init__(self, cin, cout, d_model, **mamba2_args):
        super().__init__()
        self.fc_in = nn.Linear(cin, d_model, bias=False)
        self.mamba2_for = self.Mamba2(d_model, **mamba2_args)
        self.mamba2_back = self.Mamba2(d_model, **mamba2_args)
        self.fc_out = nn.Linear(d_model, cout, bias=False)
        self.chunk_size = mamba2_args.get("chunk_size", 64)

    def forward(self, x):
        """
        Parameters
        ----------
        x : Tensor of shape (batch, channels, length)

        Returns
        -------
        Tensor of shape (batch, cout, length)
        """
        l = x.shape[2]
        pad_len = (self.chunk_size - l % self.chunk_size) % self.chunk_size
        x = F.pad(x, (0, pad_len))

        x = x.transpose(1, 2)      # (batch, length, channels)
        x = self.fc_in(x)

        x1 = self.mamba2_for(x)
        x2 = self.mamba2_back(x.flip(1)).flip(1)

        x = x1 + x2
        x = self.fc_out(x)

        x = x.transpose(1, 2)
        x = x[:, :, :l]
        return x

    @staticmethod
    def silu(x):
        return x * torch.sigmoid(x)

    class RMSNorm(nn.Module):
        """
        RMS normalization with gated activation.
        """

        def __init__(self, d: int, eps: float = 1e-5):
            super().__init__()
            self.eps = eps
            self.weight = nn.Parameter(torch.ones(d))

        def forward(self, x, z):
            x = x * BiMamba2_1D.silu(z)
            return (
                x
                * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)
                * self.weight
            )

    class Mamba2(nn.Module):
        """
        Core Mamba v2 block.
        """

        def __init__(
            self,
            d_model: int,
            n_layer: int = 2,
            d_state: int = 32,
            d_conv: int = 5,
            expand: int = 2,
            headdim: int = 32,
            chunk_size: int = 64,
        ):
            super().__init__()
            self.n_layer = n_layer
            self.d_state = d_state
            self.headdim = headdim
            self.chunk_size = chunk_size

            self.d_inner = expand * d_model
            assert self.d_inner % self.headdim == 0, (
                "d_inner must be divisible by headdim"
            )
            self.nheads = self.d_inner // self.headdim

            d_in_proj = 2 * self.d_inner + 2 * self.d_state + self.nheads
            self.in_proj = nn.Linear(d_model, d_in_proj, bias=False)

            conv_dim = self.d_inner + 2 * d_state
            self.conv1d = nn.Conv1d(
                conv_dim,
                conv_dim,
                d_conv,
                groups=conv_dim,
                padding=2,
            )

            self.dt_bias = nn.Parameter(torch.empty(self.nheads))
            self.A_log = nn.Parameter(torch.empty(self.nheads))
            self.D = nn.Parameter(torch.empty(self.nheads))

            self.norm = BiMamba2_1D.RMSNorm(self.d_inner)
            self.out_proj = nn.Linear(self.d_inner, d_model, bias=False)

            # Initialize key parameters for numerical stability
            nn.init.zeros_(self.dt_bias)
            nn.init.zeros_(self.A_log)
            nn.init.zeros_(self.D)

        def forward(self, u: torch.Tensor):
            A = -torch.exp(self.A_log)

            zxbcdt = self.in_proj(u)
            z, xBC, dt = torch.split(
                zxbcdt,
                [
                    self.d_inner,
                    self.d_inner + 2 * self.d_state,
                    self.nheads,
                ],
                dim=-1,
            )

            dt = F.softplus(dt + self.dt_bias)

            xBC = BiMamba2_1D.silu(
                self.conv1d(xBC.transpose(1, 2))
                .transpose(1, 2)[:, : u.shape[1], :]
            )

            x, B, C = torch.split(
                xBC, [self.d_inner, self.d_state, self.d_state], dim=-1
            )

            _b, _l, _hp = x.shape
            _h = _hp // self.headdim
            _p = self.headdim
            x = x.reshape(_b, _l, _h, _p)

            y = self.ssd(
                x * dt.unsqueeze(-1),
                A * dt,
                B.unsqueeze(2),
                C.unsqueeze(2),
            )

            y = y + x * self.D.unsqueeze(-1)
            y = y.reshape(_b, _l, _h * _p)

            y = self.norm(y, z)
            y = self.out_proj(y)
            return y

        def segsum(self, x: torch.Tensor) -> torch.Tensor:
            T = x.size(-1)
            device = x.device

            x = x[..., None].repeat(1, 1, 1, 1, T)
            mask = torch.tril(
                torch.ones(T, T, dtype=torch.bool, device=device),
                diagonal=-1,
            )
            x = x.masked_fill(~mask, 0)
            x_segsum = torch.cumsum(x, dim=-2)

            mask = torch.tril(
                torch.ones(T, T, dtype=torch.bool, device=device),
                diagonal=0,
            )
            x_segsum = x_segsum.masked_fill(~mask, -torch.inf)
            return x_segsum

        def ssd(self, x, A, B, C):
            chunk_size = self.chunk_size
            assert x.shape[1] % chunk_size == 0, (
                "Sequence length must be divisible by chunk_size"
            )

            x = x.reshape(
                x.shape[0],
                x.shape[1] // chunk_size,
                chunk_size,
                x.shape[2],
                x.shape[3],
            )
            B = B.reshape(
                B.shape[0],
                B.shape[1] // chunk_size,
                chunk_size,
                B.shape[2],
                B.shape[3],
            )
            C = C.reshape(
                C.shape[0],
                C.shape[1] // chunk_size,
                chunk_size,
                C.shape[2],
                C.shape[3],
            )
            A = A.reshape(
                A.shape[0],
                A.shape[1] // chunk_size,
                chunk_size,
                A.shape[2],
            )

            A = A.permute(0, 3, 1, 2)
            A_cumsum = torch.cumsum(A, dim=-1)

            L = torch.exp(self.segsum(A))
            Y_diag = torch.einsum(
                "bclhn, bcshn, bhcls, bcshp -> bclhp",
                C,
                B,
                L,
                x,
            )

            decay_states = torch.exp(
                A_cumsum[:, :, :, -1:] - A_cumsum
            )
            states = torch.einsum(
                "bclhn, bhcl, bclhp -> bchpn",
                B,
                decay_states,
                x,
            )

            initial_states = torch.zeros_like(states[:, :1])
            states = torch.cat([initial_states, states], dim=1)

            decay_chunk = torch.exp(
                self.segsum(
                    F.pad(A_cumsum[:, :, :, -1], (1, 0))
                )
            )[0]

            new_states = torch.einsum(
                "bhzc, bchpn -> bzhpn",
                decay_chunk,
                states,
            )
            states = new_states[:, :-1]

            state_decay_out = torch.exp(A_cumsum)
            Y_off = torch.einsum(
                "bclhn, bchpn, bhcl -> bclhp",
                C,
                states,
                state_decay_out,
            )

            Y = Y_diag + Y_off
            Y = Y.reshape(
                Y.shape[0],
                Y.shape[1] * Y.shape[2],
                Y.shape[3],
                Y.shape[4],
            )
            return Y

    def extract_features(self, dataset: np.ndarray, batch_size=16):
        """
        Extract pooled sequence features from the dataset.
        """
        device = next(self.parameters()).device
        self.eval()
        outputs = []

        with torch.no_grad():
            for i in range(0, len(dataset), batch_size):
                batch = dataset[i:i + batch_size]
                batch_tensor = torch.tensor(
                    batch,
                    dtype=torch.float32,
                    device=device,
                )
                if batch_tensor.ndim == 2:
                    batch_tensor = batch_tensor.unsqueeze(1)

                out = self(batch_tensor)       # (batch, cout, length)
                pooled = out.mean(dim=2)       # (batch, cout)
                outputs.append(pooled.cpu())

        return torch.cat(outputs, dim=0).numpy()


class BGC:
    """
    BGC feature fusion framework:
    CARS + CNN2D + BiMamba2_1D with optional standardization.
    """

    def __init__(
        self,
        cars: CARS,
        cnn2d: CNN2D,
        mamba: BiMamba2_1D,
        standardize=True,
    ):
        self.cars = cars
        self.cnn2d = cnn2d
        self.mamba = mamba
        self.standardize = standardize
        self.scaler = StandardScaler() if standardize else None

    def fit_transform(
        self,
        X: np.ndarray,
        y_for_cars: np.ndarray,
        batch_size=16,
    ):
        """
        Fit all submodules and return fused features.
        """
        feats_cars = self.cars.fit_transform(X, y_for_cars)
        feats_2d = self.cnn2d.extract_features(X, batch_size=batch_size)
        feats_m = self.mamba.extract_features(X, batch_size=batch_size)

        feats = np.hstack([feats_cars, feats_2d, feats_m])
        if self.scaler is not None:
            feats = self.scaler.fit_transform(feats)

        return feats

    def transform(self, X: np.ndarray, batch_size=16):
        """
        Transform new data using fitted submodules.
        """
        feats_cars = self.cars.transform(X)
        feats_2d = self.cnn2d.extract_features(X, batch_size=batch_size)
        feats_m = self.mamba.extract_features(X, batch_size=batch_size)

        feats = np.hstack([feats_cars, feats_2d, feats_m])
        if self.scaler is not None:
            feats = self.scaler.transform(feats)

        return feats
